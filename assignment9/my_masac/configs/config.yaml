actor_hidden_size: [64, 64]  # The size of hidden layers for actor network.
activation: 'leaky_relu'      # The activation function for each hidden layer.
activation_action: 'sigmoid'  # The activation function for the last layer of actor network.
agent: "MASAC"  # the learning algorithms_marl
alpha: 0.01
batch_size: 256
buffer_size: 100000
continuous_action: True  # Continuous action space or not.
critic_hidden_size: [64, 64]
device: "cuda:2"
distributed_training: False  # Whether to use multi-GPU for distributed training.
dl_toolbox: "torch"  # The deep learning toolbox. Choices: "torch", "mindspore", "tensorflow"
env_name: "mpe"  # Name of the environment.
env_id: "simple_adversary_v3"
env_seed: 1  # The random seed of the environment.
eval_interval: 100000
fps: 50  # The frames per second for the rendering videos in log file.
gamma: 0.95  # discount factor
grad_clip_norm: 0.5
learner: "MASAC_Learner"
learning_rate: 0.0004  # The learning rate.
learning_rate_actor: 0.01  # learning rate for actor
learning_rate_critic: 0.001  # learning rate for critic
log_dir: "./logs/"
logger: "wandb"  # Choices: "tensorboard", "wandb".
master_port: '12355'  # The master port for current experiment when use distributed training.
model_dir: "./models/"
parallels: 16
policy: "Gaussian_MASAC_Policy"
project_name: "My_masac"
render: True
render_mode: 'rgb_array' # Choices: 'human', 'rgb_array'.
representation: "Basic_Identical"
representation_hidden_size: []  # the units for each hidden layer
runner: "RunnerCompetition"
running_steps: 10000000
seed: 1
start_training: 1000  # start training after n steps
tau: 0.001  # soft update for target networks
test_episode: 5
test_mode: False  # Whether to run in test mode.
training_frequency: 25
use_actions_mask: False
use_grad_clip: True
use_parameter_sharing: False
use_automatic_entropy_tuning: True
vectorize: "DummyVecMultiAgentEnv"
wandb_user_name: "2036105396-nanjing-university"



