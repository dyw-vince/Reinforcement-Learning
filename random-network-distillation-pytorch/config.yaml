# [DEFAULT]
Agent: RND
EnvType: atari
EnvID: "MontezumaRevengeNoFrameskip-v4"
Device: "cuda:2"
MaxStepPerEpisode: 4500
ExtCoef: 2.0
MaxStep:  10000000
LearningRate: 0.0001
NumEnv: 128
NumStep: 128
Gamma: 0.999
IsLoadModel:  False
IsRender: False
IntGamma: 0.99
Lambda: 0.95
StableEps: 1e-8
StateStackSize: 4
PreProcHeight: 84
ProProcWidth: 84
UseGAE: True
UseGPU: True
UseNorm: False
UseNoisyNet: False
ClipGradNorm: 0.5
ClipRange: 5
Entropy: 0.001
Epoch: 4
MiniBatch: 4
PPOEps: 0.1
IntCoef: 1.0
StickyAction: True
ActionProb: 0.25
UpdateProportion: 0.25
LifeDone: False
ObsNormStep: 50
Filters: [32, 64, 64]
Kernels: [8, 4, 3]
Strides: [4, 2, 1]
FcHiddenSizes: [512, ]  # fully connected layer hidden sizes.
ActorHiddenSizes: []
CriticHiddenSizes: []
RndPredHiddenSizes:  [512,512]
RndTargetHiddenSizes: [512]
ModelPath:  "models/MontezumaRevenge.model"
PredictorPath:  "models/MontezumaRevenge.pred"
TargetPath: "models/MontezumaRevenge.target"
LogPath: "./logs/rnd/"
WandbUserName: "2036105396-nanjing-university"
ProjectName: "RND_MontezunmaRevenge"

EnvType: [atari]
